{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4726dcdd",
   "metadata": {},
   "source": [
    "# Pre-processing workflow for MPAS-Ocean model output of basal melt rate\n",
    "\n",
    "This notebook removes the linear trend (if present), seasonal signal and draft dependence of basal melt from the MPAS-Ocean SORRMv2.1 ocean model run. What remains at the end is the variability component. It adds the seasonal and variability components and saves this as a forcing file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f905036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from xeofs.xarray import EOF\n",
    "import rioxarray\n",
    "\n",
    "from shapely.geometry import mapping\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7ffcac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyprojroot import here\n",
    "\n",
    "root = here()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e2c087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aislens import dataprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ed37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Merge datasets from multiple ice shelves.\\n\\n    Args:\\n        results (list): List of xarray.Dataset objects.\\n\\n    Returns:\\n        xarray.Dataset: Merged dataset.\\n    '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5350d3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def detrend_dim(data, dim, deg):\n",
    "    # Store the original mean\n",
    "    #original_mean = data.mean(dim=dim)\n",
    "    # detrend along a single dimension\n",
    "    p = data.polyfit(dim=dim, deg=deg)\n",
    "    fit = xr.polyval(data[dim], p.polyfit_coefficients)\n",
    "    detrended = data - fit\n",
    "    # Add back the original mean\n",
    "    #detrended += original_mean\n",
    "    return detrended\n",
    "\n",
    "def clip_data(total_data, basin):\n",
    "    \"\"\"\n",
    "    Clip the map to a specific domain\n",
    "    data: input data (xarray DataArray)\n",
    "    domain: domain name (string), as defined in the ice shelf geometry file (icems)\n",
    "    \"\"\"\n",
    "    clipped_data = total_data.rio.clip(icems.loc[[basin],'geometry'].apply(mapping),icems.crs)\n",
    "    #clipped_data = clipped_data.dropna('time',how='all')\n",
    "    #clipped_data = clipped_data.dropna('y',how='all')\n",
    "    #clipped_data = clipped_data.dropna('x',how='all')\n",
    "    #clipped_data = clipped_data.drop(\"month\")\n",
    "    return clipped_data\n",
    "\n",
    "def find_ice_shelf_index(ice_shelf_name):\n",
    "    return icems[icems['name']==ice_shelf_name].index[0]\n",
    "\n",
    "def deseasonalize(data):\n",
    "    # Group data by month\n",
    "    data_month = data.groupby(\"Time.month\")\n",
    "    # Calculate climatological mean for each month\n",
    "    data_clm = data_month.mean(\"Time\")\n",
    "    # Calculate deseasonalized anomalies\n",
    "    data_anm = data_month - data_clm\n",
    "    # Add back the original mean\n",
    "    original_mean = data.mean(\"Time\")\n",
    "    data_anm += original_mean\n",
    "    return data_anm\n",
    "\n",
    "def dedraft(data, draft):\n",
    "    data_tm = data.mean(dim='Time')\n",
    "    draft_tm = draft.mean(dim='Time')\n",
    "    data_stack = data_tm.stack(z=('x', 'y'))\n",
    "    draft_stack = draft_tm.stack(z=('x', 'y'))\n",
    "    data_stack_noNaN = data_stack.fillna(0)\n",
    "    draft_stack_noNaN = draft_stack.fillna(0)\n",
    "    data_stack_noNaN_vals = data_stack_noNaN.values.reshape(-1,1)\n",
    "    draft_stack_noNaN_vals = draft_stack_noNaN.values.reshape(-1,1)\n",
    "    reg = LinearRegression().fit(draft_stack_noNaN_vals, data_stack_noNaN_vals)\n",
    "    data_pred_stack_noNaN_vals = reg.predict(draft_stack_noNaN_vals).reshape(-1)\n",
    "    data_pred_stack_noNaN = data_stack_noNaN.copy(data=data_pred_stack_noNaN_vals)\n",
    "    data_pred_stack = data_pred_stack_noNaN.where(~data_stack.isnull(), np.nan)\n",
    "    data_pred = data_pred_stack.unstack('z').transpose()\n",
    "    #data_dedraft = data - data_pred\n",
    "    return data_pred #reg.coef_, reg.intercept_, data_pred, data_dedraft\n",
    "\n",
    "# Define a function to write_crs for the xarray dataset, with the crs input parameter defaulting to a string \"epsg:3031\"\n",
    "def write_crs(ds, crs='epsg:3031'):\n",
    "    ds.rio.write_crs(crs, inplace=True)\n",
    "    return ds\n",
    "\n",
    "# Detrend the data\n",
    "\n",
    "# Method 1: Detrend the time series of spatial mean melt rate using a linear trend that is unique at each spatial point\n",
    "SORRMv21_flux_detrend_perpixel = detrend_dim(SORRMv21_flux, 'Time', 1).compute()\n",
    "#SORRMv21_flux_detrend_perpixel_ts = SORRMv21_flux_detrend_perpixel.mean(dim=['x', 'y']).compute()\n",
    "print(\"Data detrended\")\n",
    "\n",
    "# Remove the seasonal cycle\n",
    "# Deseasonalize\n",
    "SORRMv21_flux_detrend_perpixel_deseasonalize = deseasonalize(SORRMv21_flux_detrend_perpixel).compute()\n",
    "#SORRMv21_flux_detrend_perpixel_deseasonalize_ts = SORRMv21_flux_detrend_perpixel_deseasonalize.mean(dim=['x', 'y']).compute()\n",
    "print(\"Data deseasonalized\")\n",
    "\n",
    "# Remove the draft dependence\n",
    "\"\"\"\n",
    "print('Removing draft dependence...')\n",
    "iceShelfRegions = range(33,133)\n",
    "\n",
    "# write_crs for the data to be clipped\n",
    "SORRMv21_flux_detrend_perpixel_deseasonalize = write_crs(SORRMv21_flux_detrend_perpixel_deseasonalize)\n",
    "SORRMv21_draft = write_crs(SORRMv21_draft)\n",
    "\n",
    "for i in iceShelfRegions:\n",
    "    print('extracting data for catchment {}'.format(icems.name.values[i]))\n",
    "    mlt = clip_data(SORRMv21_flux_detrend_perpixel_deseasonalize, i)\n",
    "    h = clip_data(SORRMv21_draft, i)\n",
    "    mlt_tm = mlt.mean(dim='Time')\n",
    "    h_tm = h.mean(dim='Time')\n",
    "    print('calculating linear regression for catchment {}'.format(icems.name.values[i]))\n",
    "    mlt_pred = dedraft(mlt, h)\n",
    "\n",
    "    mlt_pred.name = 'draftDepenBasalMeltPred'\n",
    "    mlt_pred.attrs['long_name'] = 'Predicted flux of mass through the ocean surface based on draft dependence coefficients. Positive into ocean.'\n",
    "    mlt_pred.attrs['units'] = 'kg m^-2 s^-1'\n",
    "\n",
    "    mlt_pred.to_netcdf(main_dir / DIR_interim / 'draft_dependence/sorrm/{}_draftPred.nc'.format(icems.name.values[i]))\n",
    "    print('{} file saved'.format(icems.name.values[i]))\n",
    "\n",
    "    del mlt, h, mlt_tm, h_tm, mlt_pred\n",
    "    print('deleted interim variables')\n",
    "    gc.collect()\n",
    "print('draft dependence removed, predicted flux files saved for individual ice shelves')\n",
    "\n",
    "# Merge draft dependence parameters for all ice shelves into a single xarray dataset\n",
    "\n",
    "iceShelfRegions = range(33,133)\n",
    "ds = xr.Dataset()\n",
    "for i in iceShelfRegions:\n",
    "    ds = xr.merge([ds, xr.open_dataset(main_dir / DIR_interim / 'draft_dependence/sorrm/{}_draftPred.nc'.format(icems.name.values[i]))])\n",
    "ds.to_netcdf(main_dir / DIR_interim / 'draft_dependence/sorrm/SORRMv21_draftDependencePred.nc')\n",
    "\n",
    "print('merged draft dependence parameters for all ice shelves into a single xarray dataset')\n",
    "\"\"\"\n",
    "\n",
    "# Load the draft dependence prediction\n",
    "ds = xr.open_dataset(main_dir / DIR_interim / 'draft_dependence/sorrm/SORRMv21_draftDependencePred.nc')\n",
    "ds = ds.draftDepenBasalMeltPred\n",
    "\n",
    "# Remove draft dependence from the data\n",
    "SORRMv21_flux_detrend_perpixel_deseasonalize_dedraft = SORRMv21_flux_detrend_perpixel_deseasonalize - ds#['draftDepenBasalMeltPred']\n",
    "#SORRMv21_flux_detrend_perpixel_deseasonalize_dedraft_ts = SORRMv21_flux_detrend_perpixel_deseasonalize_dedraft.mean(dim=['x', 'y']).compute()\n",
    "\n",
    "# Save the preprocessed data\n",
    "SORRMv21_variability = SORRMv21_flux_detrend_perpixel_deseasonalize_dedraft\n",
    "\n",
    "# Rename name attribute for the variable\n",
    "#SORRMv21_variability.attrs['name'] = 'landIceFreshwaterFluxVariability'\n",
    "SORRMv21_variability.to_netcdf(main_dir / DIR_processed / 'draft_dependence/sorrm/SORRMv21_variability.nc')\n",
    "print('Preprocessed data saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4594725c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdc9ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665237ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aislens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
