{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4726dcdd",
   "metadata": {},
   "source": [
    "# Pre-processing workflow for MPAS-Ocean model output of basal melt rate\n",
    "\n",
    "This notebook removes the linear trend (if present), seasonal signal and draft dependence of basal melt from the MPAS-Ocean SORRMv2.1 ocean model run. What remains at the end is the variability component. It adds the seasonal and variability components and saves this as a forcing file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f905036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from xeofs.xarray import EOF\n",
    "import rioxarray\n",
    "\n",
    "from shapely.geometry import mapping\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7ffcac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyprojroot import here\n",
    "\n",
    "root = here()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e2c087d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'modules'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maislens\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_preprocessing\n",
      "File \u001b[0;32m~/research/aislens/AISLENS/src/aislens/modules/data_preprocessing.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spatial\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextrapolation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fill_nan_with_nearest_neighbor_vectorized\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msubset_dataset\u001b[39m(file_path, dim, start, end, output_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    Extract a subset of a NetCDF dataset based on a specified dimension and range.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m        xarray.Dataset: Subsetted dataset.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'modules'"
     ]
    }
   ],
   "source": [
    "from aislens.modules import data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53dda8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path directories\n",
    "# Load dataset\n",
    "\n",
    "main_dir = Path.cwd().parent\n",
    "DIR_external = 'data/external/'\n",
    "DIR_interim = 'data/interim/'\n",
    "DIR_processed = 'data/processed/'\n",
    "DIR_external = 'data/external/'\n",
    "\n",
    "\n",
    "FILE_MeltDraftObs = 'ANT_G1920V01_IceShelfMeltDraft.nc'\n",
    "FILE_basalMeltObs_deSeasonalized = 'obs23_melt_anm.nc'\n",
    "FILE_SORRMv21 = 'Regridded_SORRMv2.1.ISMF.FULL.nc'\n",
    "FILE_iceShelvesShape = 'iceShelves.geojson'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca57d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ocean model output\n",
    "# Load ocean model data for plotting as well\n",
    "yr1 = 300\n",
    "yr2 = 900\n",
    "SORRMv21 = xr.open_dataset(main_dir / DIR_external / 'SORRMv2.1.ISMF/regridded_output/' / FILE_SORRMv21, chunks={\"Time\":36})\n",
    "SORRMv21_flux = SORRMv21.timeMonthly_avg_landIceFreshwaterFlux[yr1*12:yr2*12]\n",
    "SORRMv21_draft = SORRMv21.timeMonthly_avg_ssh\n",
    "\n",
    "ICESHELVES_MASK = gpd.read_file(main_dir / DIR_external / FILE_iceShelvesShape)\n",
    "icems = ICESHELVES_MASK.to_crs({'init': 'epsg:3031'});\n",
    "crs = ccrs.SouthPolarStereo();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5350d3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def detrend_dim(data, dim, deg):\n",
    "    # Store the original mean\n",
    "    #original_mean = data.mean(dim=dim)\n",
    "    # detrend along a single dimension\n",
    "    p = data.polyfit(dim=dim, deg=deg)\n",
    "    fit = xr.polyval(data[dim], p.polyfit_coefficients)\n",
    "    detrended = data - fit\n",
    "    # Add back the original mean\n",
    "    #detrended += original_mean\n",
    "    return detrended\n",
    "\n",
    "def clip_data(total_data, basin):\n",
    "    \"\"\"\n",
    "    Clip the map to a specific domain\n",
    "    data: input data (xarray DataArray)\n",
    "    domain: domain name (string), as defined in the ice shelf geometry file (icems)\n",
    "    \"\"\"\n",
    "    clipped_data = total_data.rio.clip(icems.loc[[basin],'geometry'].apply(mapping),icems.crs)\n",
    "    #clipped_data = clipped_data.dropna('time',how='all')\n",
    "    #clipped_data = clipped_data.dropna('y',how='all')\n",
    "    #clipped_data = clipped_data.dropna('x',how='all')\n",
    "    #clipped_data = clipped_data.drop(\"month\")\n",
    "    return clipped_data\n",
    "\n",
    "def find_ice_shelf_index(ice_shelf_name):\n",
    "    return icems[icems['name']==ice_shelf_name].index[0]\n",
    "\n",
    "def deseasonalize(data):\n",
    "    # Group data by month\n",
    "    data_month = data.groupby(\"Time.month\")\n",
    "    # Calculate climatological mean for each month\n",
    "    data_clm = data_month.mean(\"Time\")\n",
    "    # Calculate deseasonalized anomalies\n",
    "    data_anm = data_month - data_clm\n",
    "    # Add back the original mean\n",
    "    original_mean = data.mean(\"Time\")\n",
    "    data_anm += original_mean\n",
    "    return data_anm\n",
    "\n",
    "def dedraft(data, draft):\n",
    "    data_tm = data.mean(dim='Time')\n",
    "    draft_tm = draft.mean(dim='Time')\n",
    "    data_stack = data_tm.stack(z=('x', 'y'))\n",
    "    draft_stack = draft_tm.stack(z=('x', 'y'))\n",
    "    data_stack_noNaN = data_stack.fillna(0)\n",
    "    draft_stack_noNaN = draft_stack.fillna(0)\n",
    "    data_stack_noNaN_vals = data_stack_noNaN.values.reshape(-1,1)\n",
    "    draft_stack_noNaN_vals = draft_stack_noNaN.values.reshape(-1,1)\n",
    "    reg = LinearRegression().fit(draft_stack_noNaN_vals, data_stack_noNaN_vals)\n",
    "    data_pred_stack_noNaN_vals = reg.predict(draft_stack_noNaN_vals).reshape(-1)\n",
    "    data_pred_stack_noNaN = data_stack_noNaN.copy(data=data_pred_stack_noNaN_vals)\n",
    "    data_pred_stack = data_pred_stack_noNaN.where(~data_stack.isnull(), np.nan)\n",
    "    data_pred = data_pred_stack.unstack('z').transpose()\n",
    "    #data_dedraft = data - data_pred\n",
    "    return data_pred #reg.coef_, reg.intercept_, data_pred, data_dedraft\n",
    "\n",
    "# Define a function to write_crs for the xarray dataset, with the crs input parameter defaulting to a string \"epsg:3031\"\n",
    "def write_crs(ds, crs='epsg:3031'):\n",
    "    ds.rio.write_crs(crs, inplace=True)\n",
    "    return ds\n",
    "\n",
    "# Detrend the data\n",
    "\n",
    "# Method 1: Detrend the time series of spatial mean melt rate using a linear trend that is unique at each spatial point\n",
    "SORRMv21_flux_detrend_perpixel = detrend_dim(SORRMv21_flux, 'Time', 1).compute()\n",
    "#SORRMv21_flux_detrend_perpixel_ts = SORRMv21_flux_detrend_perpixel.mean(dim=['x', 'y']).compute()\n",
    "print(\"Data detrended\")\n",
    "\n",
    "# Remove the seasonal cycle\n",
    "# Deseasonalize\n",
    "SORRMv21_flux_detrend_perpixel_deseasonalize = deseasonalize(SORRMv21_flux_detrend_perpixel).compute()\n",
    "#SORRMv21_flux_detrend_perpixel_deseasonalize_ts = SORRMv21_flux_detrend_perpixel_deseasonalize.mean(dim=['x', 'y']).compute()\n",
    "print(\"Data deseasonalized\")\n",
    "\n",
    "# Remove the draft dependence\n",
    "\"\"\"\n",
    "print('Removing draft dependence...')\n",
    "iceShelfRegions = range(33,133)\n",
    "\n",
    "# write_crs for the data to be clipped\n",
    "SORRMv21_flux_detrend_perpixel_deseasonalize = write_crs(SORRMv21_flux_detrend_perpixel_deseasonalize)\n",
    "SORRMv21_draft = write_crs(SORRMv21_draft)\n",
    "\n",
    "for i in iceShelfRegions:\n",
    "    print('extracting data for catchment {}'.format(icems.name.values[i]))\n",
    "    mlt = clip_data(SORRMv21_flux_detrend_perpixel_deseasonalize, i)\n",
    "    h = clip_data(SORRMv21_draft, i)\n",
    "    mlt_tm = mlt.mean(dim='Time')\n",
    "    h_tm = h.mean(dim='Time')\n",
    "    print('calculating linear regression for catchment {}'.format(icems.name.values[i]))\n",
    "    mlt_pred = dedraft(mlt, h)\n",
    "\n",
    "    mlt_pred.name = 'draftDepenBasalMeltPred'\n",
    "    mlt_pred.attrs['long_name'] = 'Predicted flux of mass through the ocean surface based on draft dependence coefficients. Positive into ocean.'\n",
    "    mlt_pred.attrs['units'] = 'kg m^-2 s^-1'\n",
    "\n",
    "    mlt_pred.to_netcdf(main_dir / DIR_interim / 'draft_dependence/sorrm/{}_draftPred.nc'.format(icems.name.values[i]))\n",
    "    print('{} file saved'.format(icems.name.values[i]))\n",
    "\n",
    "    del mlt, h, mlt_tm, h_tm, mlt_pred\n",
    "    print('deleted interim variables')\n",
    "    gc.collect()\n",
    "print('draft dependence removed, predicted flux files saved for individual ice shelves')\n",
    "\n",
    "# Merge draft dependence parameters for all ice shelves into a single xarray dataset\n",
    "\n",
    "iceShelfRegions = range(33,133)\n",
    "ds = xr.Dataset()\n",
    "for i in iceShelfRegions:\n",
    "    ds = xr.merge([ds, xr.open_dataset(main_dir / DIR_interim / 'draft_dependence/sorrm/{}_draftPred.nc'.format(icems.name.values[i]))])\n",
    "ds.to_netcdf(main_dir / DIR_interim / 'draft_dependence/sorrm/SORRMv21_draftDependencePred.nc')\n",
    "\n",
    "print('merged draft dependence parameters for all ice shelves into a single xarray dataset')\n",
    "\"\"\"\n",
    "\n",
    "# Load the draft dependence prediction\n",
    "ds = xr.open_dataset(main_dir / DIR_interim / 'draft_dependence/sorrm/SORRMv21_draftDependencePred.nc')\n",
    "ds = ds.draftDepenBasalMeltPred\n",
    "\n",
    "# Remove draft dependence from the data\n",
    "SORRMv21_flux_detrend_perpixel_deseasonalize_dedraft = SORRMv21_flux_detrend_perpixel_deseasonalize - ds#['draftDepenBasalMeltPred']\n",
    "#SORRMv21_flux_detrend_perpixel_deseasonalize_dedraft_ts = SORRMv21_flux_detrend_perpixel_deseasonalize_dedraft.mean(dim=['x', 'y']).compute()\n",
    "\n",
    "# Save the preprocessed data\n",
    "SORRMv21_variability = SORRMv21_flux_detrend_perpixel_deseasonalize_dedraft\n",
    "\n",
    "# Rename name attribute for the variable\n",
    "#SORRMv21_variability.attrs['name'] = 'landIceFreshwaterFluxVariability'\n",
    "SORRMv21_variability.to_netcdf(main_dir / DIR_processed / 'draft_dependence/sorrm/SORRMv21_variability.nc')\n",
    "print('Preprocessed data saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4594725c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdc9ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665237ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aislens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
